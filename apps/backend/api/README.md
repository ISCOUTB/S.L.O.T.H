# ETL Design API Service

A comprehensive FastAPI-based REST API that serves as the main interface for the ETL Design system. This service handles user authentication, file validation requests, schema management, and communication with backend processing services.

## ğŸš€ Overview

The API Service is the primary entry point for users and external applications to interact with the ETL Design system. It provides a complete REST API with authentication, user management, file upload capabilities, and real-time status tracking for validation and schema operations.

## âœ¨ Key Features

- **ğŸ” Authentication & Authorization**: JWT-based authentication with role-based access control
- **ğŸ‘¥ User Management**: Complete CRUD operations for user accounts with admin controls
- **ğŸ“‹ Schema Management**: Upload, update, and remove JSON schemas with versioning support
- **ğŸ“„ File Validation**: Upload spreadsheet files (CSV, XLSX, XLS) for validation against schemas
- **ğŸ—ï¸ Excel Parsing Workflow**: Orchestrates complete ETL process from validation to SQL generation
- **ğŸ’¾ Intelligent Caching**: Redis-based response caching for improved performance
- **ğŸ”„ Asynchronous Processing**: RabbitMQ integration for background task processing
- **ğŸ”” Real-time Notifications**: Webhook server for task completion notifications
- **ğŸŒ REST API**: Comprehensive endpoints with automatic OpenAPI documentation
- **ğŸ¥ Health Monitoring**: System health checks and status endpoints
- **ğŸ”’ Type Safety**: Full Pydantic model validation and type checking

## Architecture

The API Service acts as the communication layer between users and the processing backend:

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client Apps   â”‚â”€â”€â”€â”€â–¶â”‚   API Service   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚   RabbitMQ      â”‚
â”‚   (Web/Mobile)  â”‚     â”‚   (FastAPI)     â”‚             â”‚   (Publisher)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–²                      â”‚                                 â”‚
         â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â–¼
         â”‚              â–¼                   â–¼            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  Typechecking   â”‚
         â”‚      â”‚  Database Svc   â”‚ â”‚   PostgreSQL    â”‚  â”‚   Workers       â”‚
         â”‚      â”‚  (gRPC Proxy)   â”‚ â”‚ (Direct SQLAlch)â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
         â”‚              â”‚                    â–²                    â”‚ Results
         â”‚              â–¼                    â”‚                    â–¼
         â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚      â”‚ Redis + MongoDB â”‚          â”‚              â”‚ Webhook Server  â”‚
         â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚              â”‚  (Notifications)â”‚
         â”‚                                   â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
         â”‚                         â”‚ User Management,  â”‚           â”‚ Webhooks
         â”‚                         â”‚ Authentication,   â”‚           â”‚
         â”‚                         â”‚ Application Data  â”‚           â”‚
         â”‚                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Service Components

- **Main API Server**: REST endpoints for user interaction (Port 8000)
- **Webhook Server**: *(Planned)* Dedicated server for task completion notifications
- **Proxy Integration**: *(Future)* Proxy layer for webhook routing

### Data Flow Separation

- **Cache & Schemas**: API â†” Database Service (gRPC) â†” Redis/MongoDB  
- **Users & Auth**: API â†” PostgreSQL (Direct SQLAlchemy)
- **Task Notifications**: Workers â†’ Webhook Server â†’ Client notifications

## ğŸ—ï¸ ETL Workflow Orchestration

The API Service orchestrates different ETL workflows that can be executed independently or in combination based on user needs. The exact implementation and flow details are currently being designed.

### Available Workflows

**Data Validation**: File validation against JSON schemas via the Typechecking service

- Requires pre-defined JSON schema
- Uses RabbitMQ for asynchronous processing
- Provides detailed validation reports

**Excel Parsing**: *(Planned Integration)* Excel file processing to SQL generation via Parser services

- Independent of validation workflow
- Processes Excel formulas and data structure
- Generates SQL DDL and INSERT statements

**Combined Processing**: *(Future)* Flexible combination of validation and parsing workflows

- User-configurable workflow selection
- Can execute workflows independently or together
- Results delivered separately or combined based on requirements

### Future Workflow Endpoints *(Design in Progress)*

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/v1/workflows/*` | Workflow execution endpoints (design TBD) |
| `GET` | `/api/v1/workflows/status/{task_id}` | Track workflow progress |
| `GET` | `/api/v1/workflows/results/{task_id}` | Download workflow results |

### Integration Points

- **Typechecking Service**: Data validation and schema compliance
- **Excel Reader Service**: *(Current: REST API, Future: gRPC)* Excel file processing coordination
- **Formula Parser Service**: *(Planned)* Complex formula analysis integration
- **DDL Generator Service**: *(Planned)* Database schema generation
- **SQL Builder Service**: *(Planned)* INSERT statement generation

**Note**: The specific workflow implementation and API design are currently being developed. The Excel Reader service currently operates as a REST API but will be migrated to gRPC for consistency with other parsing services. The exact endpoints and flow will be determined based on user requirements and system architecture decisions.

## ğŸ”Œ API Endpoints

The API provides comprehensive REST endpoints with automatic OpenAPI documentation available at `/docs`.

### ğŸ” Authentication

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/v1/login/access-token` | Login and get JWT access token |
| `GET` | `/api/v1/login/test-token` | Test token validity |

### ğŸ‘¥ User Management

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/api/v1/users/info` | Get current user information |
| `GET` | `/api/v1/users/search/{username}` | Get specific user details |
| `GET` | `/api/v1/users/search` | List all users (paginated) |
| `POST` | `/api/v1/users/create` | Create new user |
| `PATCH` | `/api/v1/users/update/{username}` | Update user information |
| `DELETE` | `/api/v1/users/delete/{username}` | Delete user |

### ğŸ·ï¸ Schema Management

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/v1/schemas/upload/{import_name}` | Upload JSON schema with versioning |
| `GET` | `/api/v1/schemas/status` | Get schema upload status and metadata |
| `DELETE` | `/api/v1/schemas/remove/{import_name}` | Remove schema with rollback support |

### ğŸ“„ File Validation

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/v1/validation/upload/{import_name}` | Upload and validate spreadsheet files |
| `GET` | `/api/v1/validation/status` | Check validation task status and progress |

### ğŸ’¾ Cache Management

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/api/v1/cache` | Get cache statistics and stored keys |
| `DELETE` | `/api/v1/cache/clear` | Clear all cached data |

### ğŸ¥ Health & Monitoring

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/health` | Basic health check with service status |
| `GET` | `/health/detailed` | Detailed health info including dependencies |
| `GET` | `/metrics` | Application metrics for monitoring systems |

### ğŸ”” Webhook Endpoints *(Planned)*

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/webhooks/task-completed` | Receive task completion notifications |
| `POST` | `/webhooks/validation-results` | Receive validation task results |
| `POST` | `/webhooks/parsing-results` | Receive parsing task results |

**Note**: Webhook server will run on a separate port and be used exclusively for receiving task completion notifications from background workers. Client notifications will be implemented via WebSockets, Server-Sent Events, or similar real-time mechanisms.

## ğŸ’¡ Usage Examples

### Authentication Flow

```bash
# Login to get access token
curl -X POST "http://localhost:8000/api/v1/login/access-token" \
     -H "Content-Type: application/x-www-form-urlencoded" \
     -d "username=admin&password=admin&rol=admin"

# Use token for authenticated requests
export TOKEN="<your_access_token>"
curl -H "Authorization: Bearer $TOKEN" \
     "http://localhost:8000/api/v1/users/info"
```

### Schema Management

```bash
# Upload a JSON schema
curl -X POST "http://localhost:8000/api/v1/schemas/upload/user_data" \
     -H "Authorization: Bearer $TOKEN" \
     -H "Content-Type: application/json" \
     -d '{
       "type": "object",
       "properties": {
         "name": {"type": "string"},
         "email": {"type": "string", "format": "email"},
         "age": {"type": "integer", "minimum": 0}
       },
       "required": ["name", "email"]
     }'

# Check schema status
curl -H "Authorization: Bearer $TOKEN" \
     "http://localhost:8000/api/v1/schemas/status?import_name=user_data"
```

### File Validation

```bash
# Upload and validate a CSV file
curl -X POST "http://localhost:8000/api/v1/validation/upload/user_data" \
     -H "Authorization: Bearer $TOKEN" \
     -F "spreadsheet_file=@users.csv"

# Check validation status
curl -H "Authorization: Bearer $TOKEN" \
     "http://localhost:8000/api/v1/validation/status?import_name=user_data"
```

### User Management

```bash
# Create a new user
curl -X POST "http://localhost:8000/api/v1/users/create" \
     -H "Authorization: Bearer $TOKEN" \
     -H "Content-Type: application/json" \
     -d '{
       "username": "newuser",
       "email": "newuser@example.com",
       "full_name": "New User",
       "password": "securepassword"
     }'

# Get user information
curl -H "Authorization: Bearer $TOKEN" \
     "http://localhost:8000/api/v1/users/search/newuser"
```

## âš™ï¸ Configuration

The service uses environment variables for configuration. Create a `.env` file based on `.env.example`.

### API Configuration

```bash
# Server Settings
SERVER_HOST="localhost"
SERVER_PORT=8000
SERVER_DEBUG=false
API_V1_STR="/api/v1"
CORS_ORIGINS="http://localhost,http://localhost:3000,http://localhost:8000"

# Security
SECRET_KEY="your_secret_key_here"
FIRST_SUPERUSER="admin"
FIRST_SUPERUSER_PASSWORD="admin_password"

# Health Monitoring
HEALTH_CHECK_ENABLED=true
HEALTH_ENDPOINTS_INCLUDE_DETAILED=true

# Webhook Server (Planned)
WEBHOOK_SERVER_ENABLED=false
WEBHOOK_SERVER_HOST="localhost"
WEBHOOK_SERVER_PORT=8001
WEBHOOK_SECRET_KEY="webhook_secret_key"
```

### Database Configuration

```bash
# PostgreSQL (User Management - Direct Connection)
POSTGRES_HOST="localhost"
POSTGRES_PORT=5432
POSTGRES_USER="admin"
POSTGRES_PASSWORD="admin"
POSTGRES_DB="typechecking_db"

# Database Service (gRPC - Redis/MongoDB Operations)
DATABASE_CONNECTION_HOST="localhost"
DATABASE_CONNECTION_PORT=50050
```

### RabbitMQ Configuration

```bash
# RabbitMQ Publishing
RABBITMQ_HOST="localhost"
RABBITMQ_PORT=5672
RABBITMQ_USER="admin"
RABBITMQ_PASSWORD="admin"
RABBITMQ_VHOST="/"

# Worker Configuration
MAX_WORKERS=4
WORKER_CONCURRENCY=4
WORKER_PREFETCH_COUNT=1

# Exchange and Queues
RABBITMQ_EXCHANGE="typechecking.exchange"
RABBITMQ_EXCHANGE_TYPE="topic"
RABBITMQ_QUEUE_SCHEMAS="typechecking.schemas.queue"
RABBITMQ_QUEUE_VALIDATIONS="typechecking.validations.queue"

# Publishing Routing Keys
RABBITMQ_PUBLISHERS_ROUTING_KEY_SCHEMAS="schemas.update"
RABBITMQ_PUBLISHERS_ROUTING_KEY_VALIDATIONS="validation.request"
```

## ğŸ› ï¸ Development

### Prerequisites

- Python 3.12+
- PostgreSQL 17+
- RabbitMQ 4.0+
- Database Service running

### Installation

```bash
# Install dependencies
uv sync

# Run database migrations
uv run alembic upgrade head

# Create initial data
uv run python -m src.initial_data
```

Or just running the script [prestart.sh](./scripts/prestart.sh).

### Running the Service

```bash
# Development mode
uv run uvicorn src.main:app --host 0.0.0.0 --port 8000 --reload

# Production mode
uv run uvicorn src.main:app --host 0.0.0.0 --port 8000
```

### Testing

```bash
# Run tests
pytest

# Run with coverage
pytest --cov=src --cov-report=html
```

## ğŸ—ï¸ Project Structure

```text
api/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/               # FastAPI routes and dependencies
â”‚   â”‚   â”œâ”€â”€ routes/        # API endpoint definitions
â”‚   â”‚   â”œâ”€â”€ deps.py        # Dependency injection
â”‚   â”‚   â”œâ”€â”€ main.py        # Router configuration
â”‚   â”‚   â””â”€â”€ utils.py       # API utilities
â”‚   â”œâ”€â”€ controllers/       # Business logic layer
â”‚   â”œâ”€â”€ core/             # Configuration and database
â”‚   â”œâ”€â”€ messaging/        # RabbitMQ publisher
â”‚   â”œâ”€â”€ models/           # SQLAlchemy models
â”‚   â”œâ”€â”€ schemas/          # Pydantic models
â”‚   â”œâ”€â”€ utils/            # Utility functions
â”‚   â””â”€â”€ main.py           # Application entry point
â”œâ”€â”€ scripts/              # Deployment scripts
â”œâ”€â”€ logs/                 # Application logs
â””â”€â”€ alembic/             # Database migrations
```

## ğŸ”„ Communication Flow

### Request Processing

1. **Client Request**: HTTP request to FastAPI endpoint
2. **Authentication**: JWT token validation and user authorization
3. **Business Logic**: Controllers handle business rules and validation
4. **Database Operations**: Via Database Service (gRPC) or direct SQL
5. **Message Publishing**: Async tasks sent to RabbitMQ
6. **Response**: Immediate response with task ID for tracking

### Background Processing

1. **Message Publishing**: API publishes to RabbitMQ queues
2. **Worker Consumption**: Typechecking service consumes messages
3. **Status Updates**: Workers update task status via Database Service
4. **Result Retrieval**: Clients poll status endpoints for completion

### Real-time Notifications *(Planned)*

1. **Task Completion**: Workers publish results to temporary result queues
2. **Webhook Delivery**: Background process sends webhook to dedicated webhook server
3. **Client Notification**: Webhook server notifies clients via real-time mechanisms
4. **Proxy Integration**: *(Future)* Proxy layer for webhook routing and management

**Note**: The current implementation uses polling for status updates. Real-time notifications via webhooks are planned for improved user experience.

### Workflow Processing *(Future)*

**Current**: Data validation workflow fully implemented via Typechecking service

**Planned**: Excel parsing workflows and flexible workflow orchestration

**Design Goals**:

- Independent workflow execution options
- User-configurable processing requirements  
- Flexible result delivery (separate or combined)

**Note**: Specific workflow implementations and integration patterns are currently being designed.

## ğŸ¤ Integration Points

- **Database Service**: gRPC client for Redis/MongoDB operations
- **Typechecking Service**: RabbitMQ message publishing for async processing
- **Excel Reader Service**: *(Current: REST, Future: gRPC)* Excel file processing coordination
- **Formula Parser Service**: *(Planned)* Complex formula analysis integration
- **DDL Generator Service**: *(Planned)* Database schema generation
- **SQL Builder Service**: *(Planned)* INSERT statement generation
- **Webhook Notifications**: *(Planned)* Real-time task completion notifications
- **Frontend Applications**: REST API endpoints for UI integration
- **External Systems**: Authentication and user management for third-party apps

**Migration Notes**:

- Excel Reader currently uses REST API but will be migrated to gRPC for consistency
- Webhook system is planned to replace polling-based status checking
- Proxy integration for webhook routing will be implemented in future iterations

## Related Documentation

- [Typechecking Service](../typechecking/): Background processing workers
- [Database Service](../../connections/database/): Centralized database operations
- [Protocol Definitions](../../../packages/proto/): Shared interface specifications

<!-- A comment just to test github actions -->
